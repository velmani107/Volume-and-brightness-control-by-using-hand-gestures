In this project we are developing a volume and brightness controller using hand gestures as the input.The system uses a web camera to record images/videos and on the basis of the input, the volume of the system is controlled.The main goal of this project is to create a system which can identify human hand gestures and use the same input as the information for controlling the device.in this project we are developing a hand gesture volume controller system with the help of OpenCV ,Python  Recognize the context of an image and describe them in a natural language like English and Tamil.To make users experience better by generating automated captions.Helps to automatically generate well-formed sentences which are concise and meaningful for a large amount of images efficiently.To translate each image is accompanied by a text description and an audio reading of that text descriptionWe can use this in image indexing, Deaf and Dumb centers, Primary schools, social medias like Instagram & Facebook, and several other natural language processing applications.In vision community hand gesture is an active area research ,for the purpose of sign language recognition and human computer interaction.In this we have used some algorithms and some modules to detect the gestures of the person and these gestures are taken as the input in the system .After capturing the input from the user the image is used in the hand tracking system to check the dimensions and shape of the gesture which is received in the system.Hand tracking module plays a important role in identifying the input recorded in the system, after that classification and segmentation process is used to classify the gestures in the systemÂ Machine learning and deep learning is also used to identify the trafter this the gestures are identified from the trained data and on the basis of that data the gestures rae recognized and is used for processing of the the system to implement the functions like increase and decrease. 




